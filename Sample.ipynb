{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Data Extraction with GPT-4o and Evaluation using Prompt Flow\n",
    "\n",
    "This notebook demonstrates how to use Prompt Flow in Azure AI Studio to extract structured JSON data from documents converted to images using GPT-4o in Azure OpenAI. The extracted data is then evaluated using an evaluation Prompt Flow to ensure the data is accurate, comparing it to ground truth data.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "The notebook uses Bash and [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) to deploy all necessary Azure resources. Bash is available by default on Linux and macOS, and on Windows using [Windows Subsystem for Linux](https://docs.microsoft.com/windows/wsl/install). Alternatively, the repository includes a [devcontainer](./.devcontainer) configuration for Visual Studio Code, which includes a Linux environment with the necessary tools pre-installed.\n",
    "\n",
    "Before continuing, ensure that you have selected the **Bash** kernel for the notebook. This can be found by clicking on the kernel selector in the top right corner of the notebook, selecting **Jupyter Kernel...** and then **Bash**.\n",
    "\n",
    "![Select Bash kernel](./images/bash-kernel.png)\n",
    "\n",
    "Running this notebook will deploy the following resources in your Azure subscription:\n",
    "- Resource Group\n",
    "- Managed Identity, with the following scoped role assignments:\n",
    "  - Contributor (Resource Group) \n",
    "  - Storage Account Contributor (Storage Account)\n",
    "  - Storage Blob Data Contributor (Storage Account)\n",
    "  - Storage File Data Privileged Contributor (Storage Account)\n",
    "  - Storage Table Data Contributor (Storage Account)\n",
    "  - Key Vault Administrator (Key Vault)\n",
    "  - ACR Pull (Container Registry)\n",
    "  - ACR Push (Container Registry)\n",
    "  - Cognitive Services Contributor (AI Services)\n",
    "  - Cognitive Services OpenAI Contributor (AI Services)\n",
    "  - Azure ML Data Scientist (AI Hub/Project)\n",
    "- Storage Account, with a `document` container for storing the document images\n",
    "- Key Vault\n",
    "- Log Analytics Workspace, with an Application Insights instance\n",
    "- Container Registry\n",
    "- AI Services, with GPT-4o global standard model deployment (10K TPM)\n",
    "- AI Hub & Project\n",
    "\n",
    "These resources are deployed in a secure manner, with API key access disabled by default. Authentication and authorization are handled using Azure Role-Based Access Control (RBAC) and Managed Identity.\n",
    "\n",
    "> **IMPORTANT:** Running the sample's evaluation prompt flow for each test case defined later with GPT-4o accrues token-based charges as would be expected running this in application code. Images are converted into tokens by converting your high resolution images into separate 512px tiled images. For more information, see the [Azure OpenAI image token overview](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview#image-tokens-gpt-4-turbo-with-vision)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the environment with Azure CLI, Bicep, and Prompt Flow CLI\n",
    "\n",
    "The following will prompt you to login to your Azure account. Once logged in, the default subscription will be set, and the environment resources will be deployed.\n",
    "\n",
    "> **Note**: If you have multiple subscription, you can change the default subscription by running `az account set --subscription <subscription-id>`.\n",
    "\n",
    "The infrastructure deployment occurs at the subscription level, managing a resource group for you. The location of the deployment is set to **Sweden Central**, and this can be changed to another location that supports the GPT-4o model as a global standard deployment option. See the [`./infra/main.bicep`](./infra/main.bicep) file for more details.\n",
    "\n",
    "> **Note**: Your user identity ID will be retrieved during the deployment and used to provide the necessary role assignments to your account.\n",
    "\n",
    "Once the infrastructure deployment is complete, the Prompt Flow scenarios will be created in the AI Studio Project. The scenarios will be used to extract structured JSON data from documents converted to images using GPT-4o in Azure OpenAI and evaluate the extracted data.\n",
    "\n",
    "### Understanding the deployment\n",
    "\n",
    "#### Managed Identity\n",
    "\n",
    "A [user-assigned Managed Identity](https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/overview) is created for authenticating the Azure AI Hub and Projects with other Azure resources, including AI Services, Storage, and Key Vault, instead of using API keys.\n",
    "\n",
    "Read more about [how to configure Azure OpenAI Service with managed identities](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity).\n",
    "\n",
    "#### Storage Account\n",
    "\n",
    "A [Storage Account](https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview) is created to provide a data store for the Azure AI Hub and Project workspaces. Additionally, for this scenario, it is used to store the document images for processing.\n",
    "\n",
    "#### Key Vault\n",
    "\n",
    "A [Key Vault](https://learn.microsoft.com/en-us/azure/key-vault/general/basic-concepts) is created to store secrets, keys, and certificates used by the Azure AI Hub and Project workspaces. This resource is required, but not used in this scenario.\n",
    "\n",
    "#### Log Analytics Workspace\n",
    "\n",
    "A [Log Analytics Workspace](https://learn.microsoft.com/en-us/azure/azure-monitor/logs/data-platform-logs) is created to provide a centralized location for storing and analyzing logs from the various connected Azure resources.\n",
    "\n",
    "#### Container Registry\n",
    "\n",
    "A [Container Registry](https://learn.microsoft.com/en-us/azure/container-registry/container-registry-intro) is created to store and manage container images required for AI models used by the Azure AI Hub and Project workspaces. This resource is necessary for ideal AI environment setup, but not used in this scenario.\n",
    "\n",
    "#### AI Services\n",
    "\n",
    "An [AI Services](https://learn.microsoft.com/en-us/azure/ai-services/what-are-ai-services) resource is created to provide access to the GPT-4o model for the Azure AI Hub and Project workspaces. This resource is provided as a connection to the AI Hub and Project to be used as a reference in Prompt Flow scenarios.\n",
    "\n",
    "#### AI Hub & Project\n",
    "\n",
    "An [AI Studio Hub & Project](https://learn.microsoft.com/en-us/azure/ai-studio/what-is-ai-studio) is created to provide the necessary workspaces for building AI solution on Azure. These resources are used to create and manage Prompt Flow scenarios for document data extraction and evaluation.\n",
    "\n",
    "#### Prompt Flow Scenarios\n",
    "\n",
    "Two Prompt Flow scenarios are created in the AI Studio Project. The [Data Extraction Prompt Flow](./promptflow/document-data-extraction/flow.dag.yaml) extracts structured JSON data from documents converted to images using GPT-4o in Azure OpenAI. The extracted data is then evaluated using a [Data Extraction Evaluation Prompt Flow](./promptflow/document-data-extraction-evaluation/flow.dag.yaml) to ensure the data is accurate, comparing it to ground truth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Set necessary Azure infrastructure deployment variables\n",
    "deploymentName='doc-extract-eval-pf'\n",
    "location='swedencentral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Set the Azure deployment subscription to the default subscription (or set it manually)\n",
    "subscriptionId=$(az account list --query \"[?isDefault].id\" -o tsv)\n",
    "# subscriptionId='00000000-0000-0000-0000-000000000000' # Uncomment this line to set the subscription manually\n",
    "\n",
    "az account set --subscription $subscriptionId\n",
    "echo \"Subscription set to $subscriptionId\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run the environment setup script to deploy the Bicep template (./infra/deploy.sh), and deploy the Prompt Flow scenarios (./promptflow/deploy.sh)\n",
    "deploymentOutputs=$(./setup-environment.sh --deploymentName $deploymentName --location $location --skipInfrastructure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Data Extraction and Evaluation Prompt Flow scenarios in the Azure AI Studio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the Data Extraction Prompt Flow scenario\n",
    "\n",
    "![image.png](./images/data-extraction-flow.png)\n",
    "\n",
    "This Prompt Flow is the core logic for loading images of documents from the Azure Storage Account into the correct format for the Azure OpenAI request, and then extracting structured JSON data from the document images using the GPT-4o model and prompts.\n",
    "\n",
    "This flow is considered a [\"standard\" flow](https://microsoft.github.io/promptflow/concepts/concept-flows.html#flow-types), which represents application logic that can be deployed as a standalone endpoint for a larger AI solution.\n",
    "\n",
    "The flow consists of the following inputs:\n",
    "\n",
    "- **system_prompt** - The default instruction prompt that tailors the model to a specific task, in this example, document data extraction to structured JSON objects.\n",
    "- **extraction_prompt** - The specific scenario instruction for performing the extraction containing key rules for performing an extraction on a type of document, including the expected output JSON object schema.\n",
    "- **storage_account_name** - The name of an Azure Storage Account where document images are stored that the compute's managed identity can access with appropriate read RBAC.\n",
    "- **blob_container_name** - The name of the blob container in the Azure Storage Account where the document images are stored.\n",
    "- **temperature** - The creativity or randomness control. A lower number will result in more deterministic and focused outputs, great for accurate data extraction.\n",
    "- **top_p** - The generated token probability control. A lower number will result in the model only consider this top % probability mass for the next token, resulting in more deterministic outputs.\n",
    "\n",
    "> Note: In the deployed scenario, default values are provided using the deployed infrastructure. These can be run for your validation purposes of the Prompt Flow Python logic. When the evaluation flow runs a batch of tests later, these values will be overridden with the specific test values.\n",
    "\n",
    "The steps in the flow are as follows:\n",
    "\n",
    "1. **load_images** - The flow will create a `BlobServiceClient` to retrieve the list of blobs in the specified container and download them using the managed identity. Once downloaded, they are converted to a base64 encoded URI for the Azure OpenAI request, and returned as an array for processing. It has the following input parameters:\n",
    "   - **storage_account_name** - The name of the Azure Storage Account.\n",
    "   - **image_container_name** - The name of the blob container in the Azure Storage Account where the document images are stored.\n",
    "2. **extract_document_data** - Using the Azure OpenAI Python SDK, the flow will construct a message containing the system prompt, extraction prompt, and the base64 encoded URI for each of the document images. This message is then sent to the API for the deployed GPT-4o model for extraction. The response is then provided as an output, to be later used by the evaluation flow. It has the following input parameters:\n",
    "   - **aoai_connection** - The Prompt Flow connection to an Azure OpenAI service.\n",
    "   - **model_deployment** - The name of the GPT model to use for the extraction, in this case, GPT-4o.\n",
    "   - **system_prompt** - The default instruction prompt that tailors the model to a specific task.\n",
    "   - **extraction_prompt** - The specific scenario instruction for performing the extraction, including the expected output JSON object schema.\n",
    "   - **temperature** - The creativity or randomness control.\n",
    "   - **top_p** - The generated token probability control.\n",
    "   - **image_uris** - An array of base64 encoded URIs for the document images, provided by the `load_images` step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the Data Extraction Evaluation Prompt Flow scenario\n",
    "\n",
    "![image.png](./images/data-extraction-eval-flow.png)\n",
    "\n",
    "This flow is considered an [\"evaluation\" flow](https://microsoft.github.io/promptflow/concepts/concept-flows.html#flow-types), which enables it to be used as part of automated evaluations in the Azure AI Studio to run batch tests over a standard flow, such as the data extraction scenario.\n",
    "\n",
    "Evaluation flows take a batch of tests as a JSON lines file, and runs each test through the standard flow by providing the input parameters from the test case. These test cases allow you to establish baseline performance metrics for your extraction prompts, enabling you to experiment and improve the accuracy of your document data extraction scenarios.\n",
    "\n",
    "The [`data.jsonl` file](./tests/data.jsonl) provided demonstrates how to construct the test cases for the batch evaluation. Each test case consists of the required inputs for the standard flow, as well as the expected output JSON object. The sample test cases provided can be used later to evaluate the effectiveness of the data extraction prompt for the [`tests/Invoice.pdf`](./tests/Invoice.pdf) document.\n",
    "\n",
    "In this sample, the structure for each test case is as follows:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"system_prompt\": \"\",\n",
    "    \"extraction_prompt\": \"\",\n",
    "    \"blob_container_name\": \"\",\n",
    "    \"storage_account_name\": \"\",\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.1,\n",
    "    \"expected\": {}\n",
    "}\n",
    "```\n",
    "\n",
    "Please feel free to modify the `data.jsonl` file to include additional scenarios with a tweaked extraction prompt to test the accuracy of the data extraction.\n",
    "\n",
    "> **Note:** The expected output JSON object must be a valid JSON object that represents the known output based on a human analysis of a document.\n",
    "\n",
    "The flow consists of the following inputs:\n",
    "\n",
    "- **expected** - The JSON object that represents the expected, known output based on a human analysis of a document, also known as the ground truth or golden data.\n",
    "- **actual** - The JSON object output generated by the data extraction prompt flow using the GPT-4o model.\n",
    "\n",
    "The steps in the flow are as follows:\n",
    "\n",
    "1. **compare_results** - The flow uses the ground truth and actual JSON objects to compare each of the keys and values to determine the number of exact matches. For objects with nested objects or arrays, the flow will recursively compare each key and value to determine the number of exact matches. Once determined, the flow will output the number of exact matches as a percentage of the total number of keys and values in the ground truth JSON object. This provides a guide for evaluating the accuracy of the scenario being evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the document images to the Azure Storage Account\n",
    "\n",
    "With an understanding of the scenarios, the first step is to convert a document into images, and upload them to the Azure Storage Account. The document images will be used as input for the data extraction scenario.\n",
    "\n",
    "For this scenario, we have provided a sample invoice document, [`tests/Invoice.pdf`](./tests/Invoice.pdf), which will be converted to images and uploaded to the Azure Storage Account.\n",
    "\n",
    "To test your own documents, update the variables in the cell below with the appropriate path to your document, and update the [`data.jsonl`](./tests/data.jsonl) file with test cases that match your extraction scenarios by providing an appropriate `system_prompt`, `extraction_prompt`, and `expected` JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Variables for creating and uploading the document images\n",
    "pdf_file_path='./tests/Invoice.pdf'\n",
    "output_dir='./tests/Invoice/'\n",
    "\n",
    "storageAccountName=$(echo $deploymentOutputs | jq -r '.infrastructureOutputs.storageAccountInfo.value.name')\n",
    "documentImageContainerName=$(echo $deploymentOutputs | jq -r '.infrastructureOutputs.storageAccountInfo.value.documentImageContainerName')\n",
    "\n",
    "echo \"Storage account name: $storageAccountName\"\n",
    "echo \"Document image container name: $documentImageContainerName\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the PDF file to images\n",
    "python3 ./scripts/pdf_to_image.py $pdf_file_path $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Clear the existing document images in the Azure Blob Storage container\n",
    "az storage blob delete-batch --account-name $storageAccountName --source $documentImageContainerName --auth-mode login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Upload the images to the Azure storage account\n",
    "echo \"Uploading document images from $output_dir to the container $documentImageContainerName storage account $storageAccountName...\" >&2\n",
    "az storage blob upload-batch --account-name $storageAccountName --destination $documentImageContainerName --source $output_dir --overwrite --auth-mode login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the Azure AI Studio\n",
    "\n",
    "To continue with this sample, we will jump into the Azure AI Studio. This section will walk through using the Azure AI Studio portal UI to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Open the AI Studio Hub project URL\n",
    "resourceGroupName=$(echo $deploymentOutputs | jq -r '.infrastructureOutputs.resourceGroupInfo.value.name')\n",
    "aiHubProjectName=$(echo $deploymentOutputs | jq -r '.infrastructureOutputs.aiHubProjectInfo.value.name')\n",
    "\n",
    "url=\"https://ai.azure.com/projectflows?wsid=/subscriptions/$subscriptionId/resourcegroups/$resourceGroupName/providers/Microsoft.MachineLearningServices/workspaces/$aiHubProjectName\"\n",
    "open $url\n",
    "\n",
    "echo \"The AI Studio Hub project is available at: $url\" >&2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the test data to the Azure AI Studio project\n",
    "\n",
    "After launching the Azure AI Studio portal, follow these steps to upload the `data.jsonl` file to the project:\n",
    "\n",
    "> **Note:** Before uploading the data, ensure that the `storage_account_name` property for each test case is set to the name of the Azure Storage Account created during the infrastructure deployment. You can find the value above in the **Uploading the document images to the Azure Storage Account** section.\n",
    "\n",
    "1. Navigate to the **Components > Data** section in the main menu for the project.\n",
    "2. Click on the **New data** button.\n",
    "3. Select the **Upload files/folders** option for the Data source, and choose the `data.jsonl` file from the `tests` folder.\n",
    "    > ![image.png](./images/upload-eval-data.png)\n",
    "4. Click **Next** and provide a **Data name** for the file, such as **eval_data**.\n",
    "    - We will use this data name later when configuring the evaluation flow batch run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the custom evaluation run\n",
    "\n",
    "After uploading the test data, follow these steps to create a custom evaluation run for the data extraction evaluation scenario:\n",
    "\n",
    "1. Navigate to the **Tools > Prompt flow** section in the main menu for the project.\n",
    "2. Select the `data-extraction` flow from the list.\n",
    "    - **Note:** This is the scenario flow that performs the extraction that we will evaluate using the custom data extraction evaluation flow.\n",
    "3. In the top-right corner, click on the **Start compute session** button to initialize a serverless compute session for the evaluation.\n",
    "    - **Note:** This may take a few minutes to start. Once started, the button will change to **Compute session running**.\n",
    "4. Once the compute session is running, click on the **Evaluate > Custom evaluation** button.\n",
    "5. From this dialog, progress to the **Batch run settings** and select the **eval_data** data source that was uploaded earlier. This will map the data to the input parameters of the extraction flow.\n",
    "    > ![image.png](./images/batch-run-settings.png)\n",
    "6. From the **Evaluation settings**, select the custom **data-extraction-eval** flow from the available options.\n",
    "    > ![image.png](./images/select-evaluation.png)\n",
    "7. Once selected, configure the evaluation flows inputs to map the **actual** value to the output of the extraction flow.\n",
    "    > ![image.png](./images/configure-evaluation.png)\n",
    "8. Finally, review and submit the evaluation run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the evaluation results\n",
    "\n",
    "After submitting the evaluation run, the Azure AI Studio will process the batch of tests and provide a summary of the results. The evaluation flow will compare the actual output generated by the data extraction flow to the expected output provided in the test data.\n",
    "\n",
    "You can view the results of the evaluation run by navigating to the **Tools > Evaluation** section in the main menu for the project.\n",
    "\n",
    "![image.png](./images/evaluation-runs.png)\n",
    "\n",
    "Clicking into the run, you can view the summary of each test case, including the expected and actual outputs, as well as the results that contains the valid and invalid keys, plus the overall percentage accuracy.\n",
    "\n",
    "![image.png](./images/evaluation-run-summary.png)\n",
    "![image.png](./images/evaluation-run-details.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
